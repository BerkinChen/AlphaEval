{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[83248:MainThread](2025-05-01 21:43:20,019) INFO - qlib.Initialization - [config.py:420] - default_conf: client.\n",
      "[83248:MainThread](2025-05-01 21:43:21,630) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[83248:MainThread](2025-05-01 21:43:21,632) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/data/home/dinghj/zr-alphagen/zr-alpha-training-base/.qlib/qlib_data/cn_data')}\n"
     ]
    }
   ],
   "source": [
    "import qlib\n",
    "from qlib.data.dataset.loader import QlibDataLoader\n",
    "import numpy as np\n",
    "from gplearn.functions import make_function\n",
    "\n",
    "qlib.init(provider_uri=\"/data/home/dinghj/zr-alphagen/zr-alpha-training-base/.qlib/qlib_data/cn_data\", region='cn')\n",
    "\n",
    "# 配置时间范围（可灵活调整）\n",
    "train_start = '2020-01-01'\n",
    "train_end   = '2020-12-31'\n",
    "test_start  = '2021-01-01'\n",
    "test_end    = '2021-06-30'\n",
    "\n",
    "# 定义股票池（沪深300成份股）\n",
    "universe = \"csi300\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义特征表达式列表和名称\n",
    "feature_expressions = [\n",
    "    \"$close\",\n",
    "    \"$volume\",\n",
    "    \"$high - $low\",\n",
    "    \"Mean($close, 5)\",\n",
    "    \"Std($close, 10)\",\n",
    "    \"Rank($close, 5)\",\n",
    "    \"$close/Ref($close, 1) - 1\",\n",
    "    \"Mean($volume, 5)\",\n",
    "]\n",
    "feature_names = [\n",
    "    \"$close\",\n",
    "    \"$volume\",\n",
    "    \"$high - $low\",\n",
    "    \"Mean($close, 5)\",\n",
    "    \"Std($close, 10)\",\n",
    "    \"Rank($close, 5)\",\n",
    "    \"$close/Ref($close, 1) - 1\",\n",
    "    \"Mean($volume, 5)\",\n",
    "]\n",
    "\n",
    "# 定义标签表达式和名称（下一日收益率）\n",
    "label_expression = [\"Ref($close, -1)/$close - 1\"]\n",
    "label_names = [\"LABEL\"]\n",
    "\n",
    "# 配置 DataLoader（包含特征和标签）\n",
    "data_loader_config = {\n",
    "    \"feature\": (feature_expressions, feature_names),\n",
    "    \"label\": (label_expression, label_names)\n",
    "}\n",
    "data_loader = QlibDataLoader(config=data_loader_config)\n",
    "\n",
    "# 加载训练集和测试集数据\n",
    "train_df = data_loader.load(instruments=universe, start_time=train_start, end_time=train_end)\n",
    "test_df  = data_loader.load(instruments=universe, start_time=test_start, end_time=test_end)\n",
    "\n",
    "# 清除缺失值（由于滚动计算等可能在序列开头产生 NaN）\n",
    "train_df = train_df.dropna()\n",
    "test_df  = test_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (72734, 8) Test samples: (35330, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 提取训练集的 X 和 y\n",
    "X_train_df = train_df[\"feature\"]            # 特征部分 DataFrame\n",
    "y_train_df = train_df[\"label\"][\"LABEL\"]     # 标签 Series\n",
    "\n",
    "# 提取测试集的 X 和 y\n",
    "X_test_df = test_df[\"feature\"]\n",
    "y_test_df = test_df[\"label\"][\"LABEL\"]\n",
    "\n",
    "# 转换为 numpy 数组，以供 gplearn 使用\n",
    "X_train = X_train_df.values\n",
    "y_train = y_train_df.values\n",
    "X_test = X_test_df.values\n",
    "y_test = y_test_df.values\n",
    "\n",
    "print(\"Train samples:\", X_train.shape, \"Test samples:\", X_test.shape)\n",
    "# 输出示例: Train samples: (样本数, 8) Test samples: (样本数, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_Program' object has no attribute 'get_all_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m      8\u001b[39m transformer = SymbolicTransformer(\n\u001b[32m      9\u001b[39m     function_set=_program.QLIB_FUNCTIONS,\n\u001b[32m     10\u001b[39m     n_components=n_components,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 2) 拟合并生成新特征\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m X_train_new = transformer.transform(X_train)\n\u001b[32m     26\u001b[39m X_test_new  = transformer.transform(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/gplearn/genetic.py:476\u001b[39m, in \u001b[36mBaseSymbolic.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    472\u001b[39m n_jobs, n_programs, starts = _partition_estimators(\n\u001b[32m    473\u001b[39m     \u001b[38;5;28mself\u001b[39m.population_size, \u001b[38;5;28mself\u001b[39m.n_jobs)\n\u001b[32m    474\u001b[39m seeds = random_state.randint(MAX_INT, size=\u001b[38;5;28mself\u001b[39m.population_size)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m population = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_evolve\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_programs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                              \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                              \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[38;5;66;03m# Reduce, maintaining order across different n_jobs\u001b[39;00m\n\u001b[32m    488\u001b[39m population = \u001b[38;5;28mlist\u001b[39m(itertools.chain.from_iterable(population))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/gplearn/genetic.py:140\u001b[39m, in \u001b[36m_parallel_evolve\u001b[39m\u001b[34m(n_programs, parents, X, y, sample_weight, seeds, params)\u001b[39m\n\u001b[32m    137\u001b[39m     curr_sample_weight = sample_weight.copy()\n\u001b[32m    138\u001b[39m oob_sample_weight = curr_sample_weight.copy()\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m indices, not_indices = \u001b[43mprogram\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_all_indices\u001b[49m(n_samples,\n\u001b[32m    141\u001b[39m                                                max_samples,\n\u001b[32m    142\u001b[39m                                                random_state)\n\u001b[32m    144\u001b[39m curr_sample_weight[not_indices] = \u001b[32m0\u001b[39m\n\u001b[32m    145\u001b[39m oob_sample_weight[indices] = \u001b[32m0\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: '_Program' object has no attribute 'get_all_indices'"
     ]
    }
   ],
   "source": [
    "from gplearn.genetic import SymbolicTransformer\n",
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n",
    "from gplearn import _program\n",
    "\n",
    "# 1) 配置 Transformer\n",
    "n_components = 10\n",
    "transformer = SymbolicTransformer(\n",
    "    function_set=('Add', 'Abs', 'Mean'),\n",
    "    n_components=n_components,\n",
    "    generations=10,\n",
    "    metric='spearman',            # IC 作为 fitness\n",
    "    p_crossover=0.7,\n",
    "    p_subtree_mutation=0.1,\n",
    "    p_hoist_mutation=0.05,\n",
    "    p_point_mutation=0.1,\n",
    "    parsimony_coefficient=0.001,\n",
    "    max_samples=0.9,\n",
    "    feature_names = list(X_train_df.columns),\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# 2) 拟合并生成新特征\n",
    "transformer.fit(X_train, y_train)\n",
    "X_train_new = transformer.transform(X_train)\n",
    "X_test_new  = transformer.transform(X_test)\n",
    "\n",
    "programs = transformer._best_programs\n",
    "\n",
    "# 4) 计算每条因子的 IC 并把 X0 → 原始特征名\n",
    "records = []\n",
    "for idx, prog in enumerate(programs):\n",
    "    # LISP 风格的原始公式\n",
    "    expr = str(prog)\n",
    "    # 把 X0, X1 ... 替换成你的 feature_names\n",
    "    for i, name in enumerate(feature_names):\n",
    "        expr = expr.replace(f\"X{i}\", name)\n",
    "\n",
    "    # 训练集／测试集上的 Spearman IC\n",
    "    ic_tr = spearmanr(X_train_new[:, idx], y_train).correlation\n",
    "    ic_te = spearmanr(X_test_new[:, idx],  y_test).correlation\n",
    "\n",
    "    records.append({\n",
    "        \"factor_id\": idx,\n",
    "        \"formula\":   expr,\n",
    "        \"IC_train\":  ic_tr,\n",
    "        \"IC_test\":   ic_te,\n",
    "    })\n",
    "\n",
    "# 5) 整理成 DataFrame 并按 IC_train 排序\n",
    "result_df = pd.DataFrame(records).sort_values(\"IC_train\", ascending=False)\n",
    "\n",
    "# 6) 打印 & （可选）保存到 csv\n",
    "print(result_df.to_string(index=False))\n",
    "\n",
    "# # 如果你想保存到 CSV：\n",
    "# result_df.to_csv(\"discovered_factors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " factor_id                                                     formula  IC_train  IC_test\n",
      "         0                            add(std10, div(std10, range_hl))  0.041338 0.019815\n",
      "         1                add(std10, add(std10, div(std10, range_hl)))  0.041005 0.016199\n",
      "         5                add(std10, add(std10, div(std10, range_hl)))  0.041005 0.016199\n",
      "         9                add(std10, add(std10, div(std10, range_hl)))  0.041005 0.016199\n",
      "         8                add(std10, add(std10, div(std10, range_hl)))  0.041005 0.016199\n",
      "         7                add(std10, add(std10, div(std10, range_hl)))  0.041005 0.016199\n",
      "         3                         add(range_hl, div(std10, range_hl))  0.040738 0.015601\n",
      "         4                         add(range_hl, div(std10, range_hl))  0.040738 0.015601\n",
      "         6                         add(range_hl, div(std10, range_hl))  0.040738 0.015601\n",
      "         2 add(add(std10, div(std10, range_hl)), div(std10, range_hl))  0.040139 0.022891\n"
     ]
    }
   ],
   "source": [
    "programs = transformer._best_programs\n",
    "\n",
    "# 4) 计算每条因子的 IC 并把 X0 → 原始特征名\n",
    "records = []\n",
    "for idx, prog in enumerate(programs):\n",
    "    # LISP 风格的原始公式\n",
    "    expr = str(prog)\n",
    "    # 把 X0, X1 ... 替换成你的 feature_names\n",
    "    for i, name in enumerate(feature_names):\n",
    "        expr = expr.replace(f\"X{i}\", name)\n",
    "\n",
    "    # 训练集／测试集上的 Spearman IC\n",
    "    ic_tr = spearmanr(X_train_new[:, idx], y_train).correlation\n",
    "    ic_te = spearmanr(X_test_new[:, idx],  y_test).correlation\n",
    "\n",
    "    records.append({\n",
    "        \"factor_id\": idx,\n",
    "        \"formula\":   expr,\n",
    "        \"IC_train\":  ic_tr,\n",
    "        \"IC_test\":   ic_te,\n",
    "    })\n",
    "\n",
    "# 5) 整理成 DataFrame 并按 IC_train 排序\n",
    "result_df = pd.DataFrame(records).sort_values(\"IC_train\", ascending=False)\n",
    "\n",
    "# 6) 打印 & （可选）保存到 csv\n",
    "print(result_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([1, 1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
